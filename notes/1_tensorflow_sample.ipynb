{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility function\n",
    "#make this notebook output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and running a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable on the default graph\n",
    "reset_graph()\n",
    "\n",
    "#variables and constants\n",
    "x=tf.Variable(3, name=\"x\")\n",
    "y=tf.Variable(4, name=\"y\")\n",
    "a=tf.constant(2, name=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#are these nodes on the graph?\n",
    "print(x.graph is tf.get_default_graph())\n",
    "print(y.graph is tf.get_default_graph())\n",
    "print(a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Note: we can add nodes to a specific graph:\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())\n",
    "#if we want to remove duplicates or unwanted nodes\"\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'x:0' shape=() dtype=int32_ref>,\n",
       " <tf.Variable 'y:0' shape=() dtype=int32_ref>,\n",
       " <tf.Tensor 'a:0' shape=() dtype=int32>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variable constants are not yet initialized\n",
    "x,y,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*x*y + y +a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of lazy evaluation -->tensor of type add\n",
    "#no value of f yet\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To evaluate the graph, we open a TensorFlow session\n",
    "A TF session initializes alol variables and evaluate the graph. It puts graph operations on a CPU or GPU (or a cluster), and holds all the variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 2\n",
      "result = 42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "a_val = a.eval(session=sess) # constant does not need to be initialize\n",
    "print('a =', a_val)\n",
    "print('result =', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 2\n",
      "result = 42\n"
     ]
    }
   ],
   "source": [
    "#Run a session with automatic closing at the end --> using the with construction\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    a_val = a.eval()\n",
    "print('a =', a_val)\n",
    "print('result =', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of all variables at once\n",
    "Code can be made even shorter if we introduce a new node on the graph that takes car of initialization of all labels at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # prepare aan init node on the graph\n",
    "\n",
    "with tf.Session() as sees:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'init' type=NoOp>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init #what node was created by tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyfecycle of a node value\n",
    "When you creat a node, it only adds a value to the executing phase when you run a TensorFlow session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3) #node for constant w\n",
    "#we create 3 tensors\n",
    "x = w + 2 \n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "#what if we want to find the values of y and z?\n",
    "#code evaluate w and x twice below\n",
    "# --> TF graph would be reversed twice to compute the values of y and x\n",
    "# independently of each other --> even though both y and z use same value\n",
    "#of x\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) #10\n",
    "    print(z.eval()) #15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All node values are dropped between runs except variable values\n",
    "A variable starts its life when its initializer is run, and ends it when the session is closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do this more efficiently by telling TF to do all the calculations in one parse on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse-mode autodiff in TF\n",
    "Define a composite function:\n",
    "$$f(w) = e^{w_{20}+w_{21}\\cdot e^{w_{10}+w_{11}\\cdot e^{w_{00}+w_{01}\\cdot x}}}$$\n",
    "It's an exponent of an exponent of an exponent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(w, x):\n",
    "    f_0 = tf.exp(w[0,0]+w[0, 1]*x) # the inner-most function\n",
    "    f_1 = tf.exp(w[1,0]+w[1,1]*f_0) # the next_level function\n",
    "    f_2 = tf.exp(w[2,0]+w[2,1]*f_1) #the output function\n",
    "    \n",
    "    return f_2, f_1, f_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a fancier implementation using name scope \n",
    "#we define each layer within it's own scope\n",
    "# this is useful for later visualization of the tensorflow graph and\n",
    "#where it belongs \n",
    "def my_func(w, x):\n",
    "    with tf.name_scope(\"f_0_level\") as scope_0:\n",
    "        f_0 = tf.exp(w[0,0]+w[0, 1]*x)\n",
    "    with tf.name_scope(\"f_1_level\") as scope_1:\n",
    "        f_1 = tf.exp(w[1,0]+w[1,1]*f_0)\n",
    "    with tf.name_scope(\"f_2_level\") as scope_2:\n",
    "         f_2 = tf.exp(w[2,0]+w[2,1]*f_1)\n",
    "    return f_2, f_1, f_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's specify a point at which we want to compute the derivate. In this example we want a point where all intercepts equal zero and all slopes are ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_0 is a point at which we want to compute the function and its derivatives\n",
    "# w_0 = np.random.rand(3,2)\n",
    "w_0 = np.vstack((np.zeros(3), np.ones(3))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manual check of derivatives at  $$w = w_{0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial f}{\\partial w_{20}}=\\frac{\\partial f}{\\partial f{2}}=f_{2}(w_{0})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial f}{\\partial w_{21}}=\\frac{\\partial f}{\\partial f{2}}\\cdot f_{1}(w_{0})=f_{2}(w_{0})\\cdot f_{1}(w_{0})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial f_{2}}{\\partial w_{10}}=\\frac{\\partial f}{\\partial f{2}}\\cdot w_{21} \\cdot \\frac{\\partial f_{1}}{\\partial w_{10}} = w_{21}\\cdot f_{2}(w_{0})\\cdot f_{1}(w_{0})=f_{2}(w_{0})\\cdot f_{1}(w_{0})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial f_{2}}{\\partial w_{11}}=\\frac{\\partial f}{\\partial f{2}}\\cdot w_{21} \\cdot \\frac{\\partial f_{1}}{\\partial w_{11}} = w_{21}\\cdot f_{2}(w_{0})\\cdot f_{1}(w_{0})\\cdot f_{0}(w_{0})=f_{2}(w_{0})\\cdot f_{1}(w_{0})\\cdot f_{0}(w_{0})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial f_{2}}{\\partial w_{00}}=\\frac{\\partial f}{\\partial f{2}}\\cdot w_{21}\\frac{\\partial f_{1}}{\\partial z}\\cdot w_{11}\\cdot \\frac{\\partial f_{0}}{\\partial w_{00}}=f_{2}(w_{0})\\cdot f_{1}(w_{0})\\cdot f_{0}(w_{0})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial f_{2}}{\\partial w_{01}}=\\frac{\\partial f}{\\partial f{2}}\\cdot w_{21}\\frac{\\partial f_{1}}{\\partial z}\\cdot w_{11}\\cdot \\frac{\\partial f_{0}}{\\partial w_{01}}=f_{2}(w_{0})\\cdot f_{1}(w_{0})\\cdot f_{0}(w_{0})\\cdot 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'gradients/AddN:0' shape=(3, 2) dtype=float32>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "#variables and their initialization \n",
    "w = tf.Variable(w_0, name='w', dtype=tf.float32)\n",
    "x = tf.Variable(1.0, name='x', dtype=tf.float32, trainable=False)\n",
    "\n",
    "#we call our function and return the values for the functions\n",
    "f_2, f_1, f_0 = my_func(w, x)\n",
    "\n",
    "#Define nodes for the gradients of the outer function \n",
    "#(f2, with respect to all parameters w in a function) \n",
    "# by TensorFlow's autofiff\n",
    "grads = tf.gradients(f_2, w)\n",
    "#the evaluation above is done by simply calling tf.gradients\n",
    "#with arguments f2 (the name of the function) and the variables with\n",
    "#respect to which we want to call to compute the gradients\n",
    "\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Derivatives in 0.0377103.2 sec\n",
      " Function values =  [3814273.0, 15.154261, 2.7182817]\n",
      "Gradients = [array([[1.5712344e+08, 1.5712344e+08],\n",
      "       [5.7802488e+07, 1.5712344e+08],\n",
      "       [3.8142730e+06, 5.7802488e+07]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#here is where we run our TF graph\n",
    "#a node for the initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Run the session\n",
    "\n",
    "t_0 = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # we can run it twice\n",
    "    #first compute the function values\n",
    "    # function_vals = sess.run(f_2, f_1, f_0)\n",
    "    #then the values of the gradients\n",
    "    # gradients = sess.run(grads)\n",
    "    #or we can just use this one line syntax\n",
    "    gradients, function_vals = sess.run([grads, [f_2, f_1, f_0]])\n",
    "    \n",
    "print(\"Computed Derivatives in %f3.2 sec\" % (time.time() - t_0))\n",
    "print(\" Function values = \", function_vals)\n",
    "print(\"Gradients =\", gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'f_2_level_1/Exp:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'f_1_level_1/Exp:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'f_0_level_1/Exp:0' shape=() dtype=float32>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check that the function after the session is \n",
    "#over returns the uninitialized value of the tensor\n",
    "my_func(w_0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
